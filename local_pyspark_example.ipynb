{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pyspark Walkthrough \n",
    "\n",
    "Based off the Tutorial by Krish Naik\n",
    "[https://www.youtube.com/watch?v=WyZmM6K7ubc&list=PLZoTAELRMXVNjiiawhzZ0afHcPvC8jpcg&index=1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is Pyspark? \n",
    "\n",
    "-   Pyspark is a distributed framework used for large scale preprocesing. It uses in-memory processing which means everything is saved in RAM instead of the Hard drive. It also includes Py4j that allows devs to work with RDDs (Robust Distributed Development) in Python. \n",
    "\n",
    "What is Pyspark Pandas API?\n",
    "\n",
    "-   The Pandas API allows for parallel preprocessing but mimics the syntax of Pandas Library. It is not as fast a Pyspark since there is an additional overhead to match the Pandas syntax.\n",
    "\n",
    "When to use Pandas, Pandas API, and Pyspark?\n",
    "\n",
    "-   Pandas: smaller datasets less than a 1 million rows\n",
    "-   Pandas API: medium-sized datasets less than 10 million rows\n",
    "- Pyspark: large datasets containing 1 billion or more rows\n",
    "\n",
    "What to use for Large-Scaled ML? \n",
    "-   For distributed preprocessing and machine learning: Use PySpark and its MLlib.\n",
    "-   For larger-than-memory computations with a Pandas-like API: Use Dask.\n",
    "-   For deep learning: Use TensorFlow or PyTorch, which support efficient data loading and processing.\n",
    "-   For NLP tasks: Use Hugging Faceâ€™s datasets library with transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>House</th>\n",
       "      <th>Year</th>\n",
       "      <th>No_Classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lora</td>\n",
       "      <td>Ravenclaw</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy</td>\n",
       "      <td>Gryffindor</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donny</td>\n",
       "      <td>Slytherin</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CJ</td>\n",
       "      <td>Hufflepuff</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fname       House  Year  No_Classes\n",
       "0   Lora   Ravenclaw     4           6\n",
       "1  Happy  Gryffindor     4           5\n",
       "2  Donny   Slytherin     5           5\n",
       "3     CJ  Hufflepuff     6           7"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'fname': ['Lora', 'Happy', 'Donny', 'CJ'], 'House': ['Ravenclaw', 'Gryffindor', 'Slytherin', 'Hufflepuff'], 'Year': [4,4,5,6], 'No_Classes': [6,5,5,7]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Walkthrough').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.222:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Walkthrough</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x12b57f190>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "| fname|     house|\n",
      "+------+----------+\n",
      "|  Luna| Ravenclaw|\n",
      "| Harry|Gryffindor|\n",
      "| Draco| Slytherin|\n",
      "|Cedric|Hufflepuff|\n",
      "+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.read.option(\"header\", \"true\").csv(\"test1.csv\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pyspark.sql.dataframe.DataFrame, pandas.core.frame.DataFrame)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark), type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(fname='Luna', house='Ravenclaw'),\n",
       " Row(fname='Harry', house='Gryffindor'),\n",
       " Row(fname='Draco', house='Slytherin')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fname: string (nullable = true)\n",
      " |-- house: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pyspark df info\n",
    "\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pyspark with Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/07/04 14:48:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"DataFrame\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.222:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>DataFrame</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1183d5f70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, fname: string, House: string, Year: string, No_Classes: string]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Dataset\n",
    "\n",
    "spark.read.option('header','true').csv(\"test1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.option('header', 'true').csv('test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+----+----------+\n",
      "|_c0|fname|     House|Year|No_Classes|\n",
      "+---+-----+----------+----+----------+\n",
      "|  0| Lora| Ravenclaw|   4|         6|\n",
      "|  1|Happy|Gryffindor|   4|         5|\n",
      "|  2|Donny| Slytherin|   5|         5|\n",
      "|  3|   CJ|Hufflepuff|   6|         7|\n",
      "+---+-----+----------+----+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/03 11:51:32 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , fname, House, Year, No_Classes\n",
      " Schema: _c0, fname, House, Year, No_Classes\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/test1.csv\n"
     ]
    }
   ],
   "source": [
    "# Check the schema\n",
    "\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- fname: string (nullable = true)\n",
      " |-- House: string (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      " |-- No_Classes: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InferSchema hyperparameter: set to True otherwise datatypes will all be string\n",
    "# In this example the index is originally a string type, but after setting \n",
    "# ...InferSchema to True, the dtype is changes to integer.\n",
    "df_spark = spark.read.option('header', 'true').csv('test1.csv', inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+----+----------+\n",
      "|_c0|fname|     House|Year|No_Classes|\n",
      "+---+-----+----------+----+----------+\n",
      "|  0| Lora| Ravenclaw|   4|         6|\n",
      "|  1|Happy|Gryffindor|   4|         5|\n",
      "|  2|Donny| Slytherin|   5|         5|\n",
      "|  3|   CJ|Hufflepuff|   6|         7|\n",
      "+---+-----+----------+----+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/03 11:51:38 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , fname, House, Year, No_Classes\n",
      " Schema: _c0, fname, House, Year, No_Classes\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/test1.csv\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- fname: string (nullable = true)\n",
      " |-- House: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- No_Classes: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can also set spark.read.csv(filename, header=True, inferSchema=True) instead\n",
    "\n",
    "df_pyspark = spark.read.csv('test1.csv', header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: int, fname: string, House: string, Year: int, No_Classes: int]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- fname: string (nullable = true)\n",
      " |-- House: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- No_Classes: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pyspark.sql.dataframe.DataFrame, pyspark.sql.dataframe.DataFrame)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Type \n",
    "\n",
    "type(df_pyspark), type(df_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0', 'fname', 'House', 'Year', 'No_Classes']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List columns\n",
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/03 11:53:45 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , fname, House, Year, No_Classes\n",
      " Schema: _c0, fname, House, Year, No_Classes\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/test1.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(_c0=0, fname='Lora', House='Ravenclaw', Year=4, No_Classes=6),\n",
       " Row(_c0=1, fname='Happy', House='Gryffindor', Year=4, No_Classes=5)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[fname: string]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting columns and indices\n",
    "\n",
    "df_pyspark.select('fname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|fname|\n",
      "+-----+\n",
      "| Lora|\n",
      "|Happy|\n",
      "|Donny|\n",
      "|   CJ|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select('fname').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark.select('fname'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|_c0|fname|\n",
      "+---+-----+\n",
      "|  0| Lora|\n",
      "|  1|Happy|\n",
      "|  2|Donny|\n",
      "|  3|   CJ|\n",
      "+---+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/03 11:53:47 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , fname\n",
      " Schema: _c0, fname\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/test1.csv\n"
     ]
    }
   ],
   "source": [
    "# Select multiple columns\n",
    "\n",
    "df_pyspark.select(['_c0', 'fname']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'fname'>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark['fname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_c0', 'int'),\n",
       " ('fname', 'string'),\n",
       " ('House', 'string'),\n",
       " ('Year', 'int'),\n",
       " ('No_Classes', 'int')]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dtypes\n",
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, _c0: string, fname: string, House: string, Year: string, No_Classes: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe option\n",
    "\n",
    "\n",
    "df_pyspark.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/04 14:49:24 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "24/07/04 14:49:24 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , fname, House, Year, No_Classes\n",
      " Schema: _c0, fname, House, Year, No_Classes\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/test1.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----+----------+------------------+------------------+\n",
      "|summary|               _c0|fname|     House|              Year|        No_Classes|\n",
      "+-------+------------------+-----+----------+------------------+------------------+\n",
      "|  count|                 4|    4|         4|                 4|                 4|\n",
      "|   mean|               1.5| NULL|      NULL|              4.75|              5.75|\n",
      "| stddev|1.2909944487358056| NULL|      NULL|0.9574271077563382|0.9574271077563382|\n",
      "|    min|                 0|   CJ|Gryffindor|                 4|                 5|\n",
      "|    max|                 3| Lora| Slytherin|                 6|                 7|\n",
      "+-------+------------------+-----+----------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding columns to pyspark dataframes\n",
    "\n",
    "df_pyspark = df_pyspark.withColumn('Next_Year', df_pyspark['Year']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: int, fname: string, House: string, Year: int, No_Classes: int, Next_Year: int]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+----+----------+---------+\n",
      "|_c0|fname|     House|Year|No_Classes|Next_Year|\n",
      "+---+-----+----------+----+----------+---------+\n",
      "|  0| Lora| Ravenclaw|   4|         6|        5|\n",
      "|  1|Happy|Gryffindor|   4|         5|        5|\n",
      "|  2|Donny| Slytherin|   5|         5|        6|\n",
      "|  3|   CJ|Hufflepuff|   6|         7|        7|\n",
      "+---+-----+----------+----+----------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/04 01:42:06 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , fname, House, Year, No_Classes\n",
      " Schema: _c0, fname, House, Year, No_Classes\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/test1.csv\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "\n",
    "df_pyspark = df_pyspark.drop('Next_Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+----+----------+\n",
      "|_c0|fname|     House|Year|No_Classes|\n",
      "+---+-----+----------+----+----------+\n",
      "|  0| Lora| Ravenclaw|   4|         6|\n",
      "|  1|Happy|Gryffindor|   4|         5|\n",
      "|  2|Donny| Slytherin|   5|         5|\n",
      "|  3|   CJ|Hufflepuff|   6|         7|\n",
      "+---+-----+----------+----+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/04 01:42:11 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , fname, House, Year, No_Classes\n",
      " Schema: _c0, fname, House, Year, No_Classes\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/test1.csv\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Columns\n",
    "df_pyspark = df_pyspark.withColumnRenamed('fname', 'Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_pyspark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_pyspark\u001b[39m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_pyspark' is not defined"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/07/05 14:54:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.222:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x13e4f4a30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Practice\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'Name': ['Sarah', 'Blake', 'Gina', 'Timmy', 'Wayne', np.nan, np.nan, 'Joshua'],\n",
    "        'WorkType': ['Contract', 'Contract-To-Hire', np.nan, 'Part-time', 'Full-Time', 'Full-Time', 'Part-Time', 'Contract-To-Hire'],\n",
    "        'Age': [32, 38, 55, 23, 46, 34, 29, np.nan],\n",
    "        'YearlySalary': [np.nan, 150000, 200000, 55000, 175000, 190000, 80000, np.nan],\n",
    "        'TotalExperience': [7, 8, np.nan, 4, np.nan, 6, 5, 9]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>WorkType</th>\n",
       "      <th>Age</th>\n",
       "      <th>YearlySalary</th>\n",
       "      <th>TotalExperience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sarah</td>\n",
       "      <td>Contract</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blake</td>\n",
       "      <td>Contract-To-Hire</td>\n",
       "      <td>38.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gina</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Timmy</td>\n",
       "      <td>Part-time</td>\n",
       "      <td>23.0</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wayne</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>46.0</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Full-Time</td>\n",
       "      <td>34.0</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Part-Time</td>\n",
       "      <td>29.0</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Joshua</td>\n",
       "      <td>Contract-To-Hire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name          WorkType   Age  YearlySalary  TotalExperience\n",
       "0   Sarah          Contract  32.0           NaN              7.0\n",
       "1   Blake  Contract-To-Hire  38.0      150000.0              8.0\n",
       "2    Gina               NaN  55.0      200000.0              NaN\n",
       "3   Timmy         Part-time  23.0       55000.0              4.0\n",
       "4   Wayne         Full-Time  46.0      175000.0              NaN\n",
       "5     NaN         Full-Time  34.0      190000.0              6.0\n",
       "6     NaN         Part-Time  29.0       80000.0              5.0\n",
       "7  Joshua  Contract-To-Hire   NaN           NaN              9.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('MissingValuesDataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('MissingValuesDataset.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+----+------------+---------------+\n",
      "|_c0|  Name|        WorkType| Age|YearlySalary|TotalExperience|\n",
      "+---+------+----------------+----+------------+---------------+\n",
      "|  0| Sarah|        Contract|32.0|        NULL|            7.0|\n",
      "|  1| Blake|Contract-To-Hire|38.0|    150000.0|            8.0|\n",
      "|  2|  Gina|            NULL|55.0|    200000.0|           NULL|\n",
      "|  3| Timmy|       Part-time|23.0|     55000.0|            4.0|\n",
      "|  4| Wayne|       Full-Time|46.0|    175000.0|           NULL|\n",
      "|  5|  NULL|       Full-Time|34.0|    190000.0|            6.0|\n",
      "|  6|  NULL|       Part-Time|29.0|     80000.0|            5.0|\n",
      "|  7|Joshua|Contract-To-Hire|NULL|        NULL|            9.0|\n",
      "+---+------+----------------+----+------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/04 15:09:30 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Name, WorkType, Age, YearlySalary, TotalExperience\n",
      " Schema: _c0, Name, WorkType, Age, YearlySalary, TotalExperience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/MissingValuesDataset.csv\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+------------+---------------+\n",
      "|_c0|  Name|        WorkType|YearlySalary|TotalExperience|\n",
      "+---+------+----------------+------------+---------------+\n",
      "|  0| Sarah|        Contract|        NULL|            7.0|\n",
      "|  1| Blake|Contract-To-Hire|    150000.0|            8.0|\n",
      "|  2|  Gina|            NULL|    200000.0|           NULL|\n",
      "|  3| Timmy|       Part-time|     55000.0|            4.0|\n",
      "|  4| Wayne|       Full-Time|    175000.0|           NULL|\n",
      "|  5|  NULL|       Full-Time|    190000.0|            6.0|\n",
      "|  6|  NULL|       Part-Time|     80000.0|            5.0|\n",
      "|  7|Joshua|Contract-To-Hire|        NULL|            9.0|\n",
      "+---+------+----------------+------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/04 15:11:27 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Name, WorkType, YearlySalary, TotalExperience\n",
      " Schema: _c0, Name, WorkType, YearlySalary, TotalExperience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/MissingValuesDataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Drop columns\n",
    "df_pyspark.drop('Age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+----+------------+---------------+\n",
      "|_c0|  Name|        WorkType| Age|YearlySalary|TotalExperience|\n",
      "+---+------+----------------+----+------------+---------------+\n",
      "|  0| Sarah|        Contract|32.0|        NULL|            7.0|\n",
      "|  1| Blake|Contract-To-Hire|38.0|    150000.0|            8.0|\n",
      "|  2|  Gina|            NULL|55.0|    200000.0|           NULL|\n",
      "|  3| Timmy|       Part-time|23.0|     55000.0|            4.0|\n",
      "|  4| Wayne|       Full-Time|46.0|    175000.0|           NULL|\n",
      "|  5|  NULL|       Full-Time|34.0|    190000.0|            6.0|\n",
      "|  6|  NULL|       Part-Time|29.0|     80000.0|            5.0|\n",
      "|  7|Joshua|Contract-To-Hire|NULL|        NULL|            9.0|\n",
      "+---+------+----------------+----+------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/04 15:11:37 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Name, WorkType, Age, YearlySalary, TotalExperience\n",
      " Schema: _c0, Name, WorkType, Age, YearlySalary, TotalExperience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/MissingValuesDataset.csv\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------------+----+------------+---------------+\n",
      "|_c0| Name|        WorkType| Age|YearlySalary|TotalExperience|\n",
      "+---+-----+----------------+----+------------+---------------+\n",
      "|  1|Blake|Contract-To-Hire|38.0|    150000.0|            8.0|\n",
      "|  3|Timmy|       Part-time|23.0|     55000.0|            4.0|\n",
      "+---+-----+----------------+----+------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/04 15:12:44 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Name, WorkType, Age, YearlySalary, TotalExperience\n",
      " Schema: _c0, Name, WorkType, Age, YearlySalary, TotalExperience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/MissingValuesDataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Drop Rows with Missing Values\n",
    "\n",
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------------+----+------------+---------------+\n",
      "|_c0| Name|        WorkType| Age|YearlySalary|TotalExperience|\n",
      "+---+-----+----------------+----+------------+---------------+\n",
      "|  1|Blake|Contract-To-Hire|38.0|    150000.0|            8.0|\n",
      "|  3|Timmy|       Part-time|23.0|     55000.0|            4.0|\n",
      "+---+-----+----------------+----+------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/04 15:20:24 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Name, WorkType, Age, YearlySalary, TotalExperience\n",
      " Schema: _c0, Name, WorkType, Age, YearlySalary, TotalExperience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/MissingValuesDataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Understanding Drop method parameters\n",
    "# I can also use pyspark.dropna()\n",
    "\n",
    "'''\n",
    "Parameters: \n",
    "    - how: str -> 'any' or 'all'. I.e drop rows with any misssing data or only drop rows with all missing data\n",
    "    - thresh: int -> overwrites how parameter. Drops rows below the threshold of non-null values\n",
    "    - subset: str, tuple, or list. list of columns to drop\n",
    "'''\n",
    "\n",
    "df_pyspark.na.drop('any').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+----+------------+---------------+\n",
      "|_c0|  Name|        WorkType| Age|YearlySalary|TotalExperience|\n",
      "+---+------+----------------+----+------------+---------------+\n",
      "|  0| Sarah|        Contract|32.0|        NULL|            7.0|\n",
      "|  1| Blake|Contract-To-Hire|38.0|    150000.0|            8.0|\n",
      "|  2|  Gina|            NULL|55.0|    200000.0|           NULL|\n",
      "|  3| Timmy|       Part-time|23.0|     55000.0|            4.0|\n",
      "|  4| Wayne|       Full-Time|46.0|    175000.0|           NULL|\n",
      "|  5|  NULL|       Full-Time|34.0|    190000.0|            6.0|\n",
      "|  6|  NULL|       Part-Time|29.0|     80000.0|            5.0|\n",
      "|  7|Joshua|Contract-To-Hire|NULL|        NULL|            9.0|\n",
      "+---+------+----------------+----+------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/04 15:20:45 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Name, WorkType, Age, YearlySalary, TotalExperience\n",
      " Schema: _c0, Name, WorkType, Age, YearlySalary, TotalExperience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/MissingValuesDataset.csv\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop('all').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------------+----+------------+---------------+\n",
      "|_c0| Name|        WorkType| Age|YearlySalary|TotalExperience|\n",
      "+---+-----+----------------+----+------------+---------------+\n",
      "|  0|Sarah|        Contract|32.0|        NULL|            7.0|\n",
      "|  1|Blake|Contract-To-Hire|38.0|    150000.0|            8.0|\n",
      "|  3|Timmy|       Part-time|23.0|     55000.0|            4.0|\n",
      "|  4|Wayne|       Full-Time|46.0|    175000.0|           NULL|\n",
      "|  5| NULL|       Full-Time|34.0|    190000.0|            6.0|\n",
      "|  6| NULL|       Part-Time|29.0|     80000.0|            5.0|\n",
      "+---+-----+----------------+----+------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/04 15:25:55 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Name, WorkType, Age, YearlySalary, TotalExperience\n",
      " Schema: _c0, Name, WorkType, Age, YearlySalary, TotalExperience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/MissingValuesDataset.csv\n"
     ]
    }
   ],
   "source": [
    "# At least X non-null values should be present in each row, otherwise they are removed\n",
    "df_pyspark.na.drop(thresh=5).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------------+----+------------+---------------+\n",
      "|_c0| Name|        WorkType| Age|YearlySalary|TotalExperience|\n",
      "+---+-----+----------------+----+------------+---------------+\n",
      "|  1|Blake|Contract-To-Hire|38.0|    150000.0|            8.0|\n",
      "|  2| Gina|            NULL|55.0|    200000.0|           NULL|\n",
      "|  3|Timmy|       Part-time|23.0|     55000.0|            4.0|\n",
      "|  4|Wayne|       Full-Time|46.0|    175000.0|           NULL|\n",
      "|  5| NULL|       Full-Time|34.0|    190000.0|            6.0|\n",
      "|  6| NULL|       Part-Time|29.0|     80000.0|            5.0|\n",
      "+---+-----+----------------+----+------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/04 15:27:23 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Name, WorkType, Age, YearlySalary, TotalExperience\n",
      " Schema: _c0, Name, WorkType, Age, YearlySalary, TotalExperience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/MissingValuesDataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Drop rows that contain null values inside a particular or list of columns\n",
    "df_pyspark.na.drop(subset='YearlySalary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+----+------------+---------------+\n",
      "|_c0|  Name|        WorkType| Age|YearlySalary|TotalExperience|\n",
      "+---+------+----------------+----+------------+---------------+\n",
      "|  0| Sarah|        Contract|32.0|        NULL|            7.0|\n",
      "|  1| Blake|Contract-To-Hire|38.0|    150000.0|            8.0|\n",
      "|  2|  Gina|            NULL|55.0|    200000.0|            5.0|\n",
      "|  3| Timmy|       Part-time|23.0|     55000.0|            4.0|\n",
      "|  4| Wayne|       Full-Time|46.0|    175000.0|            5.0|\n",
      "|  5|  NULL|       Full-Time|34.0|    190000.0|            6.0|\n",
      "|  6|  NULL|       Part-Time|29.0|     80000.0|            5.0|\n",
      "|  7|Joshua|Contract-To-Hire|NULL|        NULL|            9.0|\n",
      "+---+------+----------------+----+------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/04 15:33:52 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Name, WorkType, Age, YearlySalary, TotalExperience\n",
      " Schema: _c0, Name, WorkType, Age, YearlySalary, TotalExperience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/MissingValuesDataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Filling the missing values in a specific column\n",
    "# You can also use df_pyspark.na.fill(value, subset)\n",
    "\n",
    "'''\n",
    "pyspark.sql.DataFrame.fillna \n",
    "Parameters:\n",
    "    - value: str, float, bool, or dict. The element to replace the current values with\n",
    "    - subset: str, tuple, or list. list of column names to have the nan values filled in. \n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "df_pyspark.fillna(value=5.0, subset='TotalExperience').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+----+------------+---------------+\n",
      "|_c0|  Name|        WorkType| Age|YearlySalary|TotalExperience|\n",
      "+---+------+----------------+----+------------+---------------+\n",
      "|  0| Sarah|        Contract|32.0|        NULL|            7.0|\n",
      "|  1| Blake|Contract-To-Hire|38.0|    150000.0|            8.0|\n",
      "|  2|  Gina|             N/A|55.0|    200000.0|           NULL|\n",
      "|  3| Timmy|       Part-time|23.0|     55000.0|            4.0|\n",
      "|  4| Wayne|       Full-Time|46.0|    175000.0|           NULL|\n",
      "|  5|   N/A|       Full-Time|34.0|    190000.0|            6.0|\n",
      "|  6|   N/A|       Part-Time|29.0|     80000.0|            5.0|\n",
      "|  7|Joshua|Contract-To-Hire|NULL|        NULL|            9.0|\n",
      "+---+------+----------------+----+------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/04 15:36:30 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Name, WorkType, Age, YearlySalary, TotalExperience\n",
      " Schema: _c0, Name, WorkType, Age, YearlySalary, TotalExperience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/MissingValuesDataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Replace all missing values in string columns\n",
    "\n",
    "df_pyspark.fillna(value='N/A').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+----+------------+---------------+\n",
      "|_c0|  Name|        WorkType| Age|YearlySalary|TotalExperience|\n",
      "+---+------+----------------+----+------------+---------------+\n",
      "|  0| Sarah|        Contract|32.0|         0.0|            7.0|\n",
      "|  1| Blake|Contract-To-Hire|38.0|    150000.0|            8.0|\n",
      "|  2|  Gina|            NULL|55.0|    200000.0|            0.0|\n",
      "|  3| Timmy|       Part-time|23.0|     55000.0|            4.0|\n",
      "|  4| Wayne|       Full-Time|46.0|    175000.0|            0.0|\n",
      "|  5|  NULL|       Full-Time|34.0|    190000.0|            6.0|\n",
      "|  6|  NULL|       Part-Time|29.0|     80000.0|            5.0|\n",
      "|  7|Joshua|Contract-To-Hire| 0.0|         0.0|            9.0|\n",
      "+---+------+----------------+----+------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/04 15:39:01 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Name, WorkType, Age, YearlySalary, TotalExperience\n",
      " Schema: _c0, Name, WorkType, Age, YearlySalary, TotalExperience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/MissingValuesDataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Replace missing values in all numeric columns\n",
    "\n",
    "df_pyspark.fillna(value=0.0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+----+------------+---------------+\n",
      "|_c0|  Name|        WorkType| Age|YearlySalary|TotalExperience|\n",
      "+---+------+----------------+----+------------+---------------+\n",
      "|  0| Sarah|        Contract|32.0|        NULL|            7.0|\n",
      "|  1| Blake|Contract-To-Hire|38.0|    150000.0|            8.0|\n",
      "|  2|  Gina|            NULL|55.0|    200000.0|           NULL|\n",
      "|  3| Timmy|       Part-time|23.0|     55000.0|            4.0|\n",
      "|  4| Wayne|       Full-Time|46.0|    175000.0|           NULL|\n",
      "|  5|  NULL|       Full-Time|34.0|    190000.0|            6.0|\n",
      "|  6|  NULL|       Part-Time|29.0|     80000.0|            5.0|\n",
      "|  7|Joshua|Contract-To-Hire|NULL|        NULL|            9.0|\n",
      "+---+------+----------------+----+------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/04 15:41:15 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Name, WorkType, Age, YearlySalary, TotalExperience\n",
      " Schema: _c0, Name, WorkType, Age, YearlySalary, TotalExperience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/MissingValuesDataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Notice you cannot mix different datatypes together \n",
    "# e.g. I cant replace Null values with 'Not Available' for numeric columns\n",
    "\n",
    "df_pyspark.fillna(value='N/A', subset='YearlySalary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+----+------------+---------------+\n",
      "|_c0|  Name|        WorkType| Age|YearlySalary|TotalExperience|\n",
      "+---+------+----------------+----+------------+---------------+\n",
      "|  0| Sarah|        Contract|32.0|         0.0|            7.0|\n",
      "|  1| Blake|Contract-To-Hire|38.0|    150000.0|            8.0|\n",
      "|  2|  Gina|            NULL|55.0|    200000.0|            0.0|\n",
      "|  3| Timmy|       Part-time|23.0|     55000.0|            4.0|\n",
      "|  4| Wayne|       Full-Time|46.0|    175000.0|            0.0|\n",
      "|  5|  NULL|       Full-Time|34.0|    190000.0|            6.0|\n",
      "|  6|  NULL|       Part-Time|29.0|     80000.0|            5.0|\n",
      "|  7|Joshua|Contract-To-Hire|NULL|         0.0|            9.0|\n",
      "+---+------+----------------+----+------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/04 15:43:03 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Name, WorkType, Age, YearlySalary, TotalExperience\n",
      " Schema: _c0, Name, WorkType, Age, YearlySalary, TotalExperience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/MissingValuesDataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Replace missing values through multiple (but not all) columns\n",
    "# Notice the 0 value converts to a float dtype\n",
    "df_pyspark.fillna(value=0, subset=['YearlySalary', 'TotalExperience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+----+------------+---------------+\n",
      "|_c0|  Name|        WorkType| Age|YearlySalary|TotalExperience|\n",
      "+---+------+----------------+----+------------+---------------+\n",
      "|  0| Sarah|        Contract|32.0|        NULL|            7.0|\n",
      "|  1| Blake|Contract-To-Hire|38.0|    150000.0|            8.0|\n",
      "|  2|  Gina|            NULL|55.0|    200000.0|           NULL|\n",
      "|  3| Timmy|       Part-time|23.0|     55000.0|            4.0|\n",
      "|  4| Wayne|       Full-Time|46.0|    175000.0|           NULL|\n",
      "|  5|  NULL|       Full-Time|34.0|    190000.0|            6.0|\n",
      "|  6|  NULL|       Part-Time|29.0|     80000.0|            5.0|\n",
      "|  7|Joshua|Contract-To-Hire|NULL|        NULL|            9.0|\n",
      "+---+------+----------------+----+------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/05 14:57:18 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Name, WorkType, Age, YearlySalary, TotalExperience\n",
      " Schema: _c0, Name, WorkType, Age, YearlySalary, TotalExperience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/MissingValuesDataset.csv\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class to fill missing values with mean, median, mode, etc. \n",
    "imputer = Imputer(\n",
    "    inputCols=[\"Age\", \"YearlySalary\", \"TotalExperience\"],\n",
    "    outputCols=[f\"{col_name}_imputed\" for col_name in [\"Age\", \"YearlySalary\", \"TotalExperience\"]]\n",
    ").setStrategy('median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+----+------------+---------------+-----------+--------------------+-----------------------+\n",
      "|_c0|  Name|        WorkType| Age|YearlySalary|TotalExperience|Age_imputed|YearlySalary_imputed|TotalExperience_imputed|\n",
      "+---+------+----------------+----+------------+---------------+-----------+--------------------+-----------------------+\n",
      "|  0| Sarah|        Contract|32.0|        NULL|            7.0|       32.0|            150000.0|                    7.0|\n",
      "|  1| Blake|Contract-To-Hire|38.0|    150000.0|            8.0|       38.0|            150000.0|                    8.0|\n",
      "|  2|  Gina|            NULL|55.0|    200000.0|           NULL|       55.0|            200000.0|                    6.0|\n",
      "|  3| Timmy|       Part-time|23.0|     55000.0|            4.0|       23.0|             55000.0|                    4.0|\n",
      "|  4| Wayne|       Full-Time|46.0|    175000.0|           NULL|       46.0|            175000.0|                    6.0|\n",
      "|  5|  NULL|       Full-Time|34.0|    190000.0|            6.0|       34.0|            190000.0|                    6.0|\n",
      "|  6|  NULL|       Part-Time|29.0|     80000.0|            5.0|       29.0|             80000.0|                    5.0|\n",
      "|  7|Joshua|Contract-To-Hire|NULL|        NULL|            9.0|       34.0|            150000.0|                    9.0|\n",
      "+---+------+----------------+----+------------+---------------+-----------+--------------------+-----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/05 15:06:09 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Name, WorkType, Age, YearlySalary, TotalExperience\n",
      " Schema: _c0, Name, WorkType, Age, YearlySalary, TotalExperience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/MissingValuesDataset.csv\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/07/05 15:12:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.222:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>FilterSession</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10e36c7f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Spark Session\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.appName(name=\"FilterSession\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: int, Name: string, WorkType: string, Age: double, YearlySalary: double, TotalExperience: double]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv(\"MissingValuesDataset.csv\", header=True, inferSchema=True)\n",
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, _c0: string, Name: string, WorkType: string, Age: string, YearlySalary: string, TotalExperience: string]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+----+------------+---------------+\n",
      "|_c0|  Name|        WorkType| Age|YearlySalary|TotalExperience|\n",
      "+---+------+----------------+----+------------+---------------+\n",
      "|  0| Sarah|        Contract|32.0|        NULL|            7.0|\n",
      "|  1| Blake|Contract-To-Hire|38.0|    150000.0|            8.0|\n",
      "|  2|  Gina|            NULL|55.0|    200000.0|           NULL|\n",
      "|  3| Timmy|       Part-time|23.0|     55000.0|            4.0|\n",
      "|  4| Wayne|       Full-Time|46.0|    175000.0|           NULL|\n",
      "|  5|  NULL|       Full-Time|34.0|    190000.0|            6.0|\n",
      "|  6|  NULL|       Part-Time|29.0|     80000.0|            5.0|\n",
      "|  7|Joshua|Contract-To-Hire|NULL|        NULL|            9.0|\n",
      "+---+------+----------------+----+------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/05 15:15:31 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Name, WorkType, Age, YearlySalary, TotalExperience\n",
      " Schema: _c0, Name, WorkType, Age, YearlySalary, TotalExperience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/MissingValuesDataset.csv\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_c0', 'int'),\n",
       " ('Name', 'string'),\n",
       " ('WorkType', 'string'),\n",
       " ('Age', 'double'),\n",
       " ('YearlySalary', 'double'),\n",
       " ('TotalExperience', 'double')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double dtypes are floating point numbers\n",
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------------+----+------------+---------------+\n",
      "|_c0| Name|        WorkType| Age|YearlySalary|TotalExperience|\n",
      "+---+-----+----------------+----+------------+---------------+\n",
      "|  1|Blake|Contract-To-Hire|38.0|    150000.0|            8.0|\n",
      "|  2| Gina|            NULL|55.0|    200000.0|           NULL|\n",
      "|  4|Wayne|       Full-Time|46.0|    175000.0|           NULL|\n",
      "+---+-----+----------------+----+------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/05 15:18:12 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Name, WorkType, Age, YearlySalary, TotalExperience\n",
      " Schema: _c0, Name, WorkType, Age, YearlySalary, TotalExperience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/MissingValuesDataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Filter a single column using column instances\n",
    "df_pyspark.filter(df_pyspark[\"Age\"] > 35).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------------+----+------------+---------------+\n",
      "|_c0| Name|        WorkType| Age|YearlySalary|TotalExperience|\n",
      "+---+-----+----------------+----+------------+---------------+\n",
      "|  1|Blake|Contract-To-Hire|38.0|    150000.0|            8.0|\n",
      "|  2| Gina|            NULL|55.0|    200000.0|           NULL|\n",
      "|  4|Wayne|       Full-Time|46.0|    175000.0|           NULL|\n",
      "|  5| NULL|       Full-Time|34.0|    190000.0|            6.0|\n",
      "+---+-----+----------------+----+------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/05 15:26:28 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Name, WorkType, Age, YearlySalary, TotalExperience\n",
      " Schema: _c0, Name, WorkType, Age, YearlySalary, TotalExperience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/MissingValuesDataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Filter column using sql expressions for strings\n",
    "df_pyspark.filter('YearlySalary>100000').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---------+----+------------+---------------+\n",
      "|_c0|Name| WorkType| Age|YearlySalary|TotalExperience|\n",
      "+---+----+---------+----+------------+---------------+\n",
      "|  5|NULL|Full-Time|34.0|    190000.0|            6.0|\n",
      "+---+----+---------+----+------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/05 15:36:33 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Name, WorkType, Age, YearlySalary, TotalExperience\n",
      " Schema: _c0, Name, WorkType, Age, YearlySalary, TotalExperience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/MissingValuesDataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Filter using multiple conditions through column instances\n",
    "df_pyspark.filter((df_pyspark['WorkType'] == 'Full-Time') & (df_pyspark['YearlySalary'] > 175000)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---------+----+------------+---------------+\n",
      "|_c0| Name| WorkType| Age|YearlySalary|TotalExperience|\n",
      "+---+-----+---------+----+------------+---------------+\n",
      "|  0|Sarah| Contract|32.0|        NULL|            7.0|\n",
      "|  5| NULL|Full-Time|34.0|    190000.0|            6.0|\n",
      "+---+-----+---------+----+------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/05 15:29:06 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Name, WorkType, Age, YearlySalary, TotalExperience\n",
      " Schema: _c0, Name, WorkType, Age, YearlySalary, TotalExperience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/MissingValuesDataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Filter using multiple conditions through SQL\n",
    "df_pyspark.filter(\"TotalExperience >= 6 and Age < 35\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+\n",
      "| WorkType| Age|\n",
      "+---------+----+\n",
      "|Full-Time|34.0|\n",
      "+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter using n conditions but only display specific columns\n",
    "\n",
    "df_pyspark.filter(\"YearlySalary >= 150000 and Age < 35\").select([\"WorkType\", \"Age\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------------+----+------------+---------------+\n",
      "|_c0| Name|        WorkType| Age|YearlySalary|TotalExperience|\n",
      "+---+-----+----------------+----+------------+---------------+\n",
      "|  1|Blake|Contract-To-Hire|38.0|    150000.0|            8.0|\n",
      "|  4|Wayne|       Full-Time|46.0|    175000.0|           NULL|\n",
      "|  5| NULL|       Full-Time|34.0|    190000.0|            6.0|\n",
      "+---+-----+----------------+----+------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/05 15:44:43 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Name, WorkType, Age, YearlySalary, TotalExperience\n",
      " Schema: _c0, Name, WorkType, Age, YearlySalary, TotalExperience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/MissingValuesDataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Filter using NOT (\"~\") Operation\n",
    "\n",
    "df_pyspark.filter(\n",
    "    ~(df_pyspark[\"WorkType\"] == \"Contract\")\n",
    "    &\n",
    "    ~(df_pyspark[\"YearlySalary\"] <= 100000)\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroupBy and Aggregate Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>House</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Draco</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ron</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Draco</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ron</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  Age  Experience House\n",
       "0  Draco   18           8     G\n",
       "1    Ron   17           6     G\n",
       "2  Draco   18           6     H\n",
       "3    Ron   16           8     H"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'Name': ['Draco', 'Ron', 'Draco', 'Ron'],\n",
    "        'Age': [18, 17, 18, 16],\n",
    "        'Experience': [8, 6, 6, 8],\n",
    "        'House': [\"G\", \"G\", \"H\", \"H\"]\n",
    "    }\n",
    "    )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"GroupByDataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/07/05 15:48:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.222:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>GBAF</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10f8701f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.appName(\"GBAF\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: int, Name: string, Age: int, Experience: int, House: string]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv('GroupByDataset.csv', header=True, inferSchema=True)\n",
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+----------+-----+\n",
      "|_c0| Name|Age|Experience|House|\n",
      "+---+-----+---+----------+-----+\n",
      "|  0|Draco| 18|         8|    G|\n",
      "|  1|  Ron| 17|         6|    G|\n",
      "|  2|Draco| 18|         6|    H|\n",
      "|  3|  Ron| 16|         8|    H|\n",
      "+---+-----+---+----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/05 16:00:59 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Name, Age, Experience, House\n",
      " Schema: _c0, Name, Age, Experience, House\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/GroupByDataset.csv\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------------+\n",
      "|avg(_c0)|avg(Age)|avg(Experience)|\n",
      "+--------+--------+---------------+\n",
      "|     1.5|   17.25|            7.0|\n",
      "+--------+--------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/05 16:01:02 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Age, Experience\n",
      " Schema: _c0, Age, Experience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/GroupByDataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Group by all numeric columns\n",
    "df_pyspark.groupBy().avg().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+\n",
      "| Name|sum(Experience)|\n",
      "+-----+---------------+\n",
      "|Draco|             14|\n",
      "|  Ron|             14|\n",
      "+-----+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GroupBy using Aggregrate Function\n",
    "# Parameter of .agg is a dictionary with \n",
    "# ...a column name as the key and\n",
    "# ...the specified aggregate method as the value pertaining towards the key \n",
    "df_pyspark.groupBy('Name').agg({'Experience': 'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|House|avg(Age)|\n",
      "+-----+--------+\n",
      "|    H|    17.0|\n",
      "|    G|    17.5|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group by with Aggregate Function and sorting method\n",
    "df_pyspark.groupBy('House').agg({\"Age\": \"mean\"}).sort('avg(Age)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|House|avg(Age)|\n",
      "+-----+--------+\n",
      "|    H|    17.0|\n",
      "|    G|    17.5|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Or use .mean(), .median(), .count(), etc. with select functiono  instead of .agg()\n",
    "df_pyspark.groupBy('House').mean().select(\"House\", \"avg(Age)\").sort(\"avg(Age)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+--------+---------------+\n",
      "|Age|max(_c0)|max(Age)|max(Experience)|\n",
      "+---+--------+--------+---------------+\n",
      "| 17|       1|      17|              6|\n",
      "| 16|       3|      16|              8|\n",
      "| 18|       2|      18|              8|\n",
      "+---+--------+--------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/05 16:14:23 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Age, Experience\n",
      " Schema: _c0, Age, Experience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/GroupByDataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Group By with max Values\n",
    "df_pyspark.groupBy('Age').max().sort(\"max(Experience)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+\n",
      "|Age|House|count|\n",
      "+---+-----+-----+\n",
      "| 16|    H|    1|\n",
      "| 17|    G|    1|\n",
      "| 18|    G|    1|\n",
      "| 18|    H|    1|\n",
      "+---+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GroupBy multiple columns and count the rows for each group\n",
    "\n",
    "df_pyspark.groupBy([df_pyspark['Age'], 'House']).count().sort(\"Age\", \"House\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+--------+---------------+\n",
      "| Name|max(_c0)|max(Age)|max(Experience)|\n",
      "+-----+--------+--------+---------------+\n",
      "|Draco|       2|      18|              8|\n",
      "|  Ron|       3|      17|              8|\n",
      "+-----+--------+--------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/05 16:29:28 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Name, Age, Experience\n",
      " Schema: _c0, Name, Age, Experience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/GroupByDataset.csv\n"
     ]
    }
   ],
   "source": [
    "# GroupBy the name and determine the max age and experience\n",
    "df_pyspark.groupBy('Name').max().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "| Name|count|\n",
      "+-----+-----+\n",
      "|Draco|    2|\n",
      "|  Ron|    2|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GroupBy name and count the number of rows for each name\n",
    "df_pyspark.groupBy('Name').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|House|count|\n",
      "+-----+-----+\n",
      "|    G|    2|\n",
      "|    H|    2|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GroupBy the count of students per house\n",
    "df_pyspark.groupBy('House').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|avg(Age)|\n",
      "+--------+\n",
      "|   17.25|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# .agg function without GroupBy\n",
    "\n",
    "df_pyspark.agg({\"Age\": \"mean\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+--------+---------------+\n",
      "| Name|max(_c0)|max(Age)|max(Experience)|\n",
      "+-----+--------+--------+---------------+\n",
      "|Draco|       2|      18|              8|\n",
      "|  Ron|       3|      17|              8|\n",
      "+-----+--------+--------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/05 16:40:03 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Name, Age, Experience\n",
      " Schema: _c0, Name, Age, Experience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/GroupByDataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Find th max age and experience for each name\n",
    "df_pyspark.groupBy('Name').max().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Unit Test with Pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First, create a dataframe with missing data, then apply a pytest function to transform the data.\n",
    "- Next, load in the same local dataframe, but has already been through the preprocessing step.\n",
    "- Lastly, generate a unit test to compare the results to assert they contain the same data and datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "import pyspark\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/07/06 16:34:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Function containing the spark session\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.appName('UnitTest').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.222:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>UnitTest</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x107d5e880>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('MissingValuesDataset.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+----+------------+---------------+\n",
      "|_c0|  Name|        WorkType| Age|YearlySalary|TotalExperience|\n",
      "+---+------+----------------+----+------------+---------------+\n",
      "|  0| Sarah|        Contract|32.0|        NULL|            7.0|\n",
      "|  1| Blake|Contract-To-Hire|38.0|    150000.0|            8.0|\n",
      "|  2|  Gina|            NULL|55.0|    200000.0|           NULL|\n",
      "|  3| Timmy|       Part-time|23.0|     55000.0|            4.0|\n",
      "|  4| Wayne|       Full-Time|46.0|    175000.0|           NULL|\n",
      "|  5|  NULL|       Full-Time|34.0|    190000.0|            6.0|\n",
      "|  6|  NULL|       Part-Time|29.0|     80000.0|            5.0|\n",
      "|  7|Joshua|Contract-To-Hire|NULL|        NULL|            9.0|\n",
      "+---+------+----------------+----+------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/06 16:41:44 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Name, WorkType, Age, YearlySalary, TotalExperience\n",
      " Schema: _c0, Name, WorkType, Age, YearlySalary, TotalExperience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/MissingValuesDataset.csv\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Name: str\n",
    "WorkType: str\n",
    "Age: int\n",
    "YearsWithCompany: int\n",
    "AnnualPay: float (double)\n",
    "\n",
    "\n",
    "dropna\n",
    "fillna\n",
    "fillna with agg\n",
    "filter\n",
    "groupby\n",
    "\n",
    "'''\n",
    "df_pyspark_dropna = df_pyspark.dropna(thresh=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark_fillna_total_experience = df_pyspark_dropna.fillna(value=0.0, subset=\"TotalExperience\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------------+----+------------+---------------+\n",
      "|_c0| Name|        WorkType| Age|YearlySalary|TotalExperience|\n",
      "+---+-----+----------------+----+------------+---------------+\n",
      "|  0|Sarah|        Contract|32.0|        NULL|            7.0|\n",
      "|  1|Blake|Contract-To-Hire|38.0|    150000.0|            8.0|\n",
      "|  3|Timmy|       Part-time|23.0|     55000.0|            4.0|\n",
      "|  4|Wayne|       Full-Time|46.0|    175000.0|            0.0|\n",
      "|  5| NULL|       Full-Time|34.0|    190000.0|            6.0|\n",
      "|  6| NULL|       Part-Time|29.0|     80000.0|            5.0|\n",
      "+---+-----+----------------+----+------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/07/06 17:21:37 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Name, WorkType, Age, YearlySalary, TotalExperience\n",
      " Schema: _c0, Name, WorkType, Age, YearlySalary, TotalExperience\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/druestaples/projects/ner-chatbot-transformer/MissingValuesDataset.csv\n"
     ]
    }
   ],
   "source": [
    "df_pyspark_fillna_total_experience.fillna(value='mean', subset='YearlySalary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ner-chatbot-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
